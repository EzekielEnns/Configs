{ config, pkgs,  ... }:

#TODO move containers to new model
#
/*
use this to fetch the model
nix store prefetch-file --hash-type sha256 --json \
  "https://huggingface.co/bartowski/L3-8B-Stheno-v3.2-GGUF/resolve/main/L3-8B-Stheno-v3.2-Q4_K_S.gguf"
*/
  # steno8bQ4 = pkgs.fetchurl {
  #   url = "https://huggingface.co/bartowski/L3-8B-Stheno-v3.2-GGUF/resolve/main/L3-8B-Stheno-v3.2-Q4_K_S.gguf";
  #   sha256 = "sha256-IjSxc3Sx9HgbZjwD3yTSvGT8hHTEJ7fKMYlIU15l4lk=";
  # };
    {
    imports = [];
    config = {

        services.ollama = {
            enable = true;
            acceleration = "cuda";
            host = "0.0.0.0";
        };

        services.jellyfin.enable = true;
        systemd.tmpfiles.rules = [
            # World-writable + sticky bit (1xxx). Owned by root is typical.
            "d /srv/media         1777 root root - -"
            "d /srv/media/movies  1777 root root - -"
            "d /srv/media/tv      1777 root root - -"
            "d /srv/media/anime   1777 root root - -"
            "d /srv/media/shows   1777 root root - -"
            # Ensure/repair ownership & mode at boot (recursively for the top dir)
            "Z /srv/media         1777 root root - -"
        ];

        services.openssh = {
            enable = true;
            settings = {
                PasswordAuthentication = true;
                PermitRootLogin = "yes";
                X11Forwarding = true;
            };
        };


        hardware = {
            graphics = {
                enable = true;
                enable32Bit = true;
            };
            nvidia-container-toolkit.enable=true;
            steam-hardware.enable = true;
            #show gpu temps nvidia-smi
            # nix-shell -p pciutils --run "lspci | grep -E 'VGA|3D'"
            nvidia = {
                modesetting.enable = true;
                powerManagement.enable = true;
                open = false;
                nvidiaSettings = true;
                package = config.boot.kernelPackages.nvidiaPackages.production;
                prime = {
                    offload.enable = true;
                    amdgpuBusId = "PCI:15:0:0"; # from 0f:00.0
                    nvidiaBusId = "PCI:1:0:0";  # from 01:00.0
                };
            };
        };
        services.xserver.videoDrivers = [ "amdgpu" "nvidia"];


        # /etc/xng/settings.yml will be generated by Nix
        environment.etc."searxng/settings.yml".text = ''
use_default_settings: true

server:
  secret_key: "ba84d4236c87f611e894c4e5dedb88c8ab9632bc868cc521bbdb84ce1f625232"

search:
  formats: [html, json]

doi_resolvers:
  doi.org: "https://doi.org/"
default_doi_resolver: "doi.org"
        '';

        virtualisation.docker.enable = true;
        virtualisation.docker.enableOnBoot = true; 

        virtualisation.docker.daemon.settings = {
            features.cdi = true;
        };
        virtualisation.oci-containers = {
            backend = "docker";
            containers = {
                xng = { 
                    image = "searxng/searxng:latest";
                    ports = [ "127.0.0.1:8088:8080" ];
                    volumes = [ "/etc/searxng/settings.yml:/etc/searxng/settings.yml:ro" ];
                    environment = { SEARXNG_SETTINGS_PATH = "/etc/searxng/settings.yml"; };
                };


                ai = {
                    image = "ghcr.io/open-webui/open-webui:main";
                    extraOptions = [ "--network=host" ];
                    volumes = [ "/var/lib/openwebui:/app/backend/data" ];
                    environment = { 
                        RAG_WEB_SEARCH_ENGINE = "searxng";
                        RAG_WEB_SEARCH_RESULT_COUNT = "3";
                        RAG_WEB_SEARCH_CONCURRENT_REQUESTS = "10";
                        SEARXNG_QUERY_URL = "http://127.0.0.1:8088/search?q=<query>&format=json";
                        OLLAMA_BASE_URL = "http://localhost:11434"; 
                    };
                };
                mm = {
                    image = "neosmemo/memos:stable";
                    ports = [ "127.0.0.1:5230:5230" ];
                    volumes = [ "/var/lib/memos:/var/opt/memos" ];
                };

                kcpp = {
                    image = "koboldai/koboldcpp:latest";
                    ports = [ "127.0.0.1:5001:5001" ];
                    extraOptions = [
                        "--device=nvidia.com/gpu=all"  # <-- CDI way, matches your working docker run
                        # optional but sometimes helpful for perf:
                        "--ipc=host"
                    ];
                    volumes = [
                        "/var/lib/kcpp/models:/models"   # writable: keep downloads
                        "/var/lib/kcpp/state:/data"      # optional server-side artifacts
                    ];

                    environment = { 
                        KCPP_MODEL = "https://huggingface.co/bartowski/L3-8B-Stheno-v3.2-GGUF/resolve/main/L3-8B-Stheno-v3.2-Q4_K_S.gguf";
                        KCPP_DONT_REMOVE_MODELS = "true";
                    };
  # cmd = [
  #   "--port" "5001"
  #   "--usecublas"
  #   "--gpulayers" "32"  # adjust after we see VRAM usage
  # ];
                };
            };
        };


        services.nginx = {
            enable = true;
            recommendedProxySettings = true;
            virtualHosts = {
                "xng.lan" = {
                    serverName = "xng.lan";
                    locations."/" = {
                        proxyPass = "http://127.0.0.1:8088";
                    };
                };
                "ai.lan" = {
                    serverName = "ai.lan";
                    locations."/" = {
                        proxyPass = "http://127.0.0.1:8080";
                        proxyWebsockets = true;
                    };
                };
                "mm.lan" = {
                    serverName = "mm.lan";
                    locations."/" = {
                        proxyPass = "http://127.0.0.1:5230";
                    };
                };
                "jf.lan" = {
                    serverName = "jf.lan";
                    locations."/" = {
                        proxyPass = "http://127.0.0.1:8096";
                        proxyWebsockets = true; 
                    };
                };

                "kcpp.lan" = {
                    serverName = "kcpp.lan";
                    locations."/" = {
                        proxyPass = "http://127.0.0.1:5001";
                        proxyWebsockets = true; 
                    };
                };
            };
        };
        /*
on mac you need to add the server to dns under settings-> network -> details
then do sudo mkdir -p /etc/resolver && sudo nvim /etc/resolver/lan 
add nameserver 192.168.1.6
use this to test
scutil --dns | grep lan -A3
dig ai.lan
curl ai.lan
remebmer to add the dns to the router, also browsers require http://*.lan they will not auto fill
*/
        services.dnsmasq = {
            enable = true;

            resolveLocalQueries = false; 

            settings = {
                # Bind on loopback + your LAN IP
                "listen-address" = [ "127.0.0.1" "192.168.1.6" ];

                # Upstream resolvers (Cloudflare) -> lets you check online with real dns
                server = [ "1.1.1.1" "1.0.0.1" ];

                # Pin local names to your host's LAN IP
                address = [
                    "/xng.lan/192.168.1.6"
                    "/ai.lan/192.168.1.6"
                    "/mm.lan/192.168.1.6"
                    "/jf.lan/192.168.1.6"
                    "/kcpp.lan/192.168.1.6"
                ];

                # Sensible DNS hygiene
                "domain-needed" = true;
                "bogus-priv"   = true;
            };
        };

        networking.interfaces.enp6s0.wakeOnLan = {
            enable = true;
        };
        networking.networkmanager.enable = true;
        networking.networkmanager.unmanaged = ["enp6s0"];
        networking.firewall.allowedUDPPorts = [ 53 ];
        networking.firewall.allowedTCPPorts = [ 53 8096  22 80 443 11434 8554 ];
    };
}

